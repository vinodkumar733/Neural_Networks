{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b94d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2114add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt=pd.read_csv(\"gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0fee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e010096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "gt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddbf5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb51a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b49d8cef20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=\"CDP\",y=\"TEY\",data=gt)#which is linerly co-related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e675a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19763d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 247., 2671.,  474.,  528., 7145.,  462.,  989., 1215., 1160.,\n",
       "         148.]),\n",
       " array([100.17 , 107.614, 115.058, 122.502, 129.946, 137.39 , 144.834,\n",
       "        152.278, 159.722, 167.166, 174.61 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(gt['TEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0955e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here according to question the target variable is TEY i.e(Turbine Energy Yeild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5e6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1dc384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_gt=scaler.fit_transform(gt)\n",
    "df=pd.DataFrame(standardized_gt, columns=gt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8739bb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.231172</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.230541</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.426381</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.415642</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.516089</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.481343</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.428277</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "            TEY       CDP        CO       NOX  \n",
       "0     -1.231172 -1.357331  0.532012  1.387845  \n",
       "1     -1.229909 -1.363676  0.568733  1.393002  \n",
       "2     -1.230541 -1.360957  0.552938  1.363586  \n",
       "3     -1.229909 -1.356424  0.548933  1.382878  \n",
       "4     -1.229909 -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...       ...  \n",
       "15034 -1.426381 -1.543161  1.145792  1.085751  \n",
       "15035 -1.415642 -1.513247  1.293578  1.119943  \n",
       "15036 -1.516089 -1.467922  2.695925  2.170062  \n",
       "15037 -1.481343 -1.422598  1.924683  2.391165  \n",
       "15038 -1.428277 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1953eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6214d536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.913654e-16</td>\n",
       "      <td>-1.875504e-14</td>\n",
       "      <td>2.570219e-16</td>\n",
       "      <td>1.511894e-16</td>\n",
       "      <td>-7.559468e-17</td>\n",
       "      <td>-3.260021e-15</td>\n",
       "      <td>1.640405e-15</td>\n",
       "      <td>1.081004e-15</td>\n",
       "      <td>1.965462e-16</td>\n",
       "      <td>3.779734e-17</td>\n",
       "      <td>4.233302e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "      <td>-2.779497e+00</td>\n",
       "      <td>-1.806771e+00</td>\n",
       "      <td>-5.021933e+00</td>\n",
       "      <td>-4.188141e+00</td>\n",
       "      <td>-2.149097e+00</td>\n",
       "      <td>-1.992416e+00</td>\n",
       "      <td>-8.874862e-01</td>\n",
       "      <td>-3.861033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "      <td>-6.266930e-01</td>\n",
       "      <td>-5.091458e-01</td>\n",
       "      <td>-2.540512e-01</td>\n",
       "      <td>-4.101146e-01</td>\n",
       "      <td>-3.919003e-01</td>\n",
       "      <td>-4.354335e-01</td>\n",
       "      <td>-5.015202e-01</td>\n",
       "      <td>-6.578107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "      <td>-1.854065e-02</td>\n",
       "      <td>-8.075681e-02</td>\n",
       "      <td>2.965544e-01</td>\n",
       "      <td>5.712570e-01</td>\n",
       "      <td>-2.580448e-02</td>\n",
       "      <td>-7.011925e-02</td>\n",
       "      <td>-2.620452e-01</td>\n",
       "      <td>-1.518527e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "      <td>4.612196e-01</td>\n",
       "      <td>4.228638e-01</td>\n",
       "      <td>7.382490e-01</td>\n",
       "      <td>5.928675e-01</td>\n",
       "      <td>4.236815e-01</td>\n",
       "      <td>4.311680e-01</td>\n",
       "      <td>8.455882e-02</td>\n",
       "      <td>5.486567e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "      <td>4.486233e+00</td>\n",
       "      <td>2.871006e+00</td>\n",
       "      <td>1.028678e+00</td>\n",
       "      <td>6.627839e-01</td>\n",
       "      <td>2.553607e+00</td>\n",
       "      <td>2.700105e+00</td>\n",
       "      <td>1.895949e+01</td>\n",
       "      <td>4.937717e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT            AP            AH          AFDP          GTEP  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean   4.913654e-16 -1.875504e-14  2.570219e-16  1.511894e-16 -7.559468e-17   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00 -2.779497e+00 -1.806771e+00   \n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01 -6.266930e-01 -5.091458e-01   \n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01 -1.854065e-02 -8.075681e-02   \n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01  4.612196e-01  4.228638e-01   \n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00  4.486233e+00  2.871006e+00   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean  -3.260021e-15  1.640405e-15  1.081004e-15  1.965462e-16  3.779734e-17   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -5.021933e+00 -4.188141e+00 -2.149097e+00 -1.992416e+00 -8.874862e-01   \n",
       "25%   -2.540512e-01 -4.101146e-01 -3.919003e-01 -4.354335e-01 -5.015202e-01   \n",
       "50%    2.965544e-01  5.712570e-01 -2.580448e-02 -7.011925e-02 -2.620452e-01   \n",
       "75%    7.382490e-01  5.928675e-01  4.236815e-01  4.311680e-01  8.455882e-02   \n",
       "max    1.028678e+00  6.627839e-01  2.553607e+00  2.700105e+00  1.895949e+01   \n",
       "\n",
       "                NOX  \n",
       "count  1.503900e+04  \n",
       "mean   4.233302e-16  \n",
       "std    1.000033e+00  \n",
       "min   -3.861033e+00  \n",
       "25%   -6.578107e-01  \n",
       "50%   -1.518527e-01  \n",
       "75%    5.486567e-01  \n",
       "max    4.937717e+00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfce17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop([\"TEY\"],axis=1)\n",
    "y=df[\"TEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc085ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "            CDP        CO       NOX  \n",
       "0     -1.357331  0.532012  1.387845  \n",
       "1     -1.363676  0.568733  1.393002  \n",
       "2     -1.360957  0.552938  1.363586  \n",
       "3     -1.356424  0.548933  1.382878  \n",
       "4     -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...  \n",
       "15034 -1.543161  1.145792  1.085751  \n",
       "15035 -1.513247  1.293578  1.119943  \n",
       "15036 -1.467922  2.695925  2.170062  \n",
       "15037 -1.422598  1.924683  2.391165  \n",
       "15038 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e7b2b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -1.231172\n",
       "1       -1.229909\n",
       "2       -1.230541\n",
       "3       -1.229909\n",
       "4       -1.229909\n",
       "           ...   \n",
       "15034   -1.426381\n",
       "15035   -1.415642\n",
       "15036   -1.516089\n",
       "15037   -1.481343\n",
       "15038   -1.428277\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7284dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c75a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features =X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2708141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=n_features, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    #here we take loss func as means_squared_error coz its regression classifier\n",
    "    optmizer =RMSprop(0.03)#Learning_rate is 0.03\n",
    "    model.compile(loss='mean_squared_error', optimizer=optmizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cf61dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod kumar N\\AppData\\Local\\Temp\\ipykernel_18312\\1728840933.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  36.5s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  33.3s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  33.7s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  34.2s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  33.4s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 2.6min\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 2.6min\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 2.8min\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 2.7min\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 2.7min\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 4.8min\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 3.5min\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 3.6min\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 3.6min\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 3.8min\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  13.0s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  12.9s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  12.9s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  12.9s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  12.8s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  54.3s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  51.1s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  52.0s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  51.0s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  50.6s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 2.1min\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 2.2min\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.9min\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.6min\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.6min\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.6s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   7.9s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   7.2s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.6s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.6s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  26.6s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  25.2s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  25.6s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  26.2s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  25.6s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  50.6s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  49.7s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  51.5s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  50.6s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  59.6s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e016d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d9a4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we get best batch size as 10 and best epoch as 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee3d513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = n_features,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = n_features,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss='mean_squared_error',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc22b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod kumar N\\AppData\\Local\\Temp\\ipykernel_18312\\3634346431.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  24.6s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  21.3s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  21.0s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  21.2s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  21.6s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  21.6s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  21.3s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  21.2s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  21.3s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  21.6s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  21.2s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  20.8s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  22.0s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  22.0s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  22.0s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  23.1s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  22.6s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  22.9s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  22.7s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  23.4s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  22.8s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  22.7s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  22.5s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  22.4s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  22.5s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  22.4s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  22.1s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  22.2s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  22.6s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  23.4s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  22.6s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  22.6s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  22.5s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  22.6s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  22.6s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  22.7s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  23.0s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  22.4s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  22.4s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  22.8s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  22.4s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  23.2s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  22.5s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  22.5s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  22.5s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14b9dc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6f6cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):#to determine the no for hidden layers neuron\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = n_features,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    optmizer =RMSprop(0.001)#here,Learning_rate is 0.03\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22cd93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod kumar N\\AppData\\Local\\Temp\\ipykernel_18312\\553030313.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[CV 1/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 1/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time=  20.3s\n",
      "[CV 2/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 2/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time=  21.0s\n",
      "[CV 3/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 3/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time=  18.9s\n",
      "[CV 4/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 4/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time=  18.7s\n",
      "[CV 5/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 5/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time=  18.8s\n",
      "[CV 1/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 1/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time=  18.7s\n",
      "[CV 2/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 2/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time=  18.9s\n",
      "[CV 3/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 3/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time=  16.9s\n",
      "[CV 4/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 4/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time=  16.2s\n",
      "[CV 5/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 5/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time=  16.4s\n",
      "[CV 1/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 1/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time=  16.0s\n",
      "[CV 2/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 2/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time=  16.2s\n",
      "[CV 3/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 3/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time=  16.2s\n",
      "[CV 4/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 4/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time=  16.2s\n",
      "[CV 5/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 5/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time=  17.8s\n",
      "[CV 1/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 1/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time=  17.4s\n",
      "[CV 2/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 2/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time=  17.3s\n",
      "[CV 3/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 3/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time=  17.5s\n",
      "[CV 4/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 4/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time=  17.3s\n",
      "[CV 5/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 5/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time=  17.7s\n",
      "[CV 1/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 1/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time=  18.2s\n",
      "[CV 2/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 2/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time=  17.5s\n",
      "[CV 3/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 3/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time=  17.3s\n",
      "[CV 4/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 4/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time=  17.9s\n",
      "[CV 5/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 5/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time=  17.4s\n",
      "[CV 1/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 1/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time=  17.3s\n",
      "[CV 2/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 2/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time=  17.4s\n",
      "[CV 3/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 3/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time=  17.5s\n",
      "[CV 4/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 4/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time=  18.3s\n",
      "[CV 5/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 5/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time=  18.9s\n",
      "[CV 1/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 1/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time=  18.5s\n",
      "[CV 2/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 2/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time=  19.8s\n",
      "[CV 3/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 3/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time=  21.0s\n",
      "[CV 4/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 4/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time=  21.5s\n",
      "[CV 5/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 5/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time=  21.9s\n",
      "[CV 1/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 1/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time=  21.9s\n",
      "[CV 2/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 2/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time=  21.2s\n",
      "[CV 3/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 3/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time=  23.8s\n",
      "[CV 4/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 4/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time=  22.0s\n",
      "[CV 5/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 5/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time=  24.3s\n",
      "[CV 1/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 1/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time=  24.2s\n",
      "[CV 2/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 2/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time=  23.3s\n",
      "[CV 3/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 3/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time=  24.6s\n",
      "[CV 4/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 4/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time=  24.2s\n",
      "[CV 5/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 5/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time=  20.7s\n",
      "[CV 1/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 1/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time=  18.4s\n",
      "[CV 2/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 2/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time=  18.4s\n",
      "[CV 3/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 3/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time=  18.1s\n",
      "[CV 4/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 4/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time=  18.3s\n",
      "[CV 5/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 5/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time=  18.5s\n",
      "[CV 1/5; 11/56] START neuron1=8, neuron2=8......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time=  18.1s\n",
      "[CV 2/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 2/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time=  19.2s\n",
      "[CV 3/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 3/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time=  19.1s\n",
      "[CV 4/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 4/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time=  17.6s\n",
      "[CV 5/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 5/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time=  18.0s\n",
      "[CV 1/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 1/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time=  16.8s\n",
      "[CV 2/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 2/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time=  18.0s\n",
      "[CV 3/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 3/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time=  16.7s\n",
      "[CV 4/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 4/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time=  16.9s\n",
      "[CV 5/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 5/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time=  17.1s\n",
      "[CV 1/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 1/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time=  17.8s\n",
      "[CV 2/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 2/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time=  17.6s\n",
      "[CV 3/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 3/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time=  17.5s\n",
      "[CV 4/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 4/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time=  17.5s\n",
      "[CV 5/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 5/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time=  17.5s\n",
      "[CV 1/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 1/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time=  17.9s\n",
      "[CV 2/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 2/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time=  17.7s\n",
      "[CV 3/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 3/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time=  17.4s\n",
      "[CV 4/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 4/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time=  17.9s\n",
      "[CV 5/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 5/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time=  17.6s\n",
      "[CV 1/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 1/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time=  18.8s\n",
      "[CV 2/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 2/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time=  17.6s\n",
      "[CV 3/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 3/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time=  17.5s\n",
      "[CV 4/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 4/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time=  17.7s\n",
      "[CV 5/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 5/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time=  17.3s\n",
      "[CV 1/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 1/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time=  17.2s\n",
      "[CV 2/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 2/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time=  18.9s\n",
      "[CV 3/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 3/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time=  18.6s\n",
      "[CV 4/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 4/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time=  18.7s\n",
      "[CV 5/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 5/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time=  19.1s\n",
      "[CV 1/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 1/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time=  19.5s\n",
      "[CV 2/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 2/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time=  18.6s\n",
      "[CV 3/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 3/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time=  18.6s\n",
      "[CV 4/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 4/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time=  18.6s\n",
      "[CV 5/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 5/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time=  18.8s\n",
      "[CV 1/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 1/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time=  18.4s\n",
      "[CV 2/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 2/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time=  18.8s\n",
      "[CV 3/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 3/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time=  18.6s\n",
      "[CV 4/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 4/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time=  18.5s\n",
      "[CV 5/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 5/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time=  18.7s\n",
      "[CV 1/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 1/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time=  18.6s\n",
      "[CV 2/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 2/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time=  18.3s\n",
      "[CV 3/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 3/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time=  18.4s\n",
      "[CV 4/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 4/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time=  19.3s\n",
      "[CV 5/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 5/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time=  18.6s\n",
      "[CV 1/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 1/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time=  18.8s\n",
      "[CV 2/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 2/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time=  29.9s\n",
      "[CV 3/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 3/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time=  34.1s\n",
      "[CV 4/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 4/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time=  33.3s\n",
      "[CV 5/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 5/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time=  35.7s\n",
      "[CV 1/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 1/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time=  35.7s\n",
      "[CV 2/5; 21/56] START neuron1=16, neuron2=30....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time=  35.3s\n",
      "[CV 3/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 3/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time=  37.4s\n",
      "[CV 4/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 4/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time=  35.6s\n",
      "[CV 5/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 5/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time=  36.7s\n",
      "[CV 1/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 1/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time=  35.4s\n",
      "[CV 2/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 2/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time=  36.7s\n",
      "[CV 3/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 3/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time=  35.9s\n",
      "[CV 4/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 4/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time=  36.5s\n",
      "[CV 5/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 5/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time=  35.7s\n",
      "[CV 1/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 1/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time=  34.4s\n",
      "[CV 2/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 2/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time=  36.5s\n",
      "[CV 3/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 3/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time=  28.6s\n",
      "[CV 4/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 4/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time=  35.9s\n",
      "[CV 5/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 5/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time=  36.8s\n",
      "[CV 1/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 1/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time=  37.9s\n",
      "[CV 2/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 2/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time=  35.7s\n",
      "[CV 3/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 3/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time=  35.7s\n",
      "[CV 4/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 4/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time=  35.9s\n",
      "[CV 5/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 5/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time=  28.5s\n",
      "[CV 1/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 1/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time=  36.9s\n",
      "[CV 2/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 2/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time=  37.3s\n",
      "[CV 3/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 3/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time=  35.3s\n",
      "[CV 4/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 4/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time=  34.9s\n",
      "[CV 5/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 5/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time=  35.5s\n",
      "[CV 1/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 1/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time=  35.6s\n",
      "[CV 2/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 2/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time=  36.5s\n",
      "[CV 3/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 3/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time=  38.3s\n",
      "[CV 4/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 4/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time=  33.5s\n",
      "[CV 5/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 5/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time=  36.6s\n",
      "[CV 1/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 1/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time=  37.6s\n",
      "[CV 2/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 2/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time=  37.1s\n",
      "[CV 3/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 3/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time=  35.2s\n",
      "[CV 4/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 4/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time=  36.6s\n",
      "[CV 5/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 5/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time=  34.0s\n",
      "[CV 1/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 1/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time=  33.2s\n",
      "[CV 2/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 2/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time=  36.0s\n",
      "[CV 3/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 3/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time=  35.4s\n",
      "[CV 4/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 4/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time=  35.5s\n",
      "[CV 5/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 5/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time=  35.9s\n",
      "[CV 1/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 1/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time=  36.1s\n",
      "[CV 2/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 2/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time=  34.3s\n",
      "[CV 3/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 3/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time=  35.8s\n",
      "[CV 4/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 4/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time=  35.9s\n",
      "[CV 5/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 5/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time=  38.4s\n",
      "[CV 1/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 1/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time=  36.1s\n",
      "[CV 2/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 2/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time=  35.6s\n",
      "[CV 3/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 3/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time=  35.9s\n",
      "[CV 4/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 4/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time=  38.2s\n",
      "[CV 5/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 5/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time=  35.7s\n",
      "[CV 1/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 1/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time=  31.4s\n",
      "[CV 2/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 2/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time=  34.6s\n",
      "[CV 3/5; 31/56] START neuron1=20, neuron2=50....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time=  35.0s\n",
      "[CV 4/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 4/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time=  36.1s\n",
      "[CV 5/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 5/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time=  37.4s\n",
      "[CV 1/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 1/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time=  35.9s\n",
      "[CV 2/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 2/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time=  36.0s\n",
      "[CV 3/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 3/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time=  35.5s\n",
      "[CV 4/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 4/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time=  36.3s\n",
      "[CV 5/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 5/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time=  36.6s\n",
      "[CV 1/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 1/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time=  34.8s\n",
      "[CV 2/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 2/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time=  35.8s\n",
      "[CV 3/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 3/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time=  30.8s\n",
      "[CV 4/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 4/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time=  35.3s\n",
      "[CV 5/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 5/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time=  32.9s\n",
      "[CV 1/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 1/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time=  38.3s\n",
      "[CV 2/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 2/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time=  40.0s\n",
      "[CV 3/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 3/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time=  36.2s\n",
      "[CV 4/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 4/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time=  35.1s\n",
      "[CV 5/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 5/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time=  35.1s\n",
      "[CV 1/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 1/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  34.9s\n",
      "[CV 2/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 2/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  37.3s\n",
      "[CV 3/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 3/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  39.0s\n",
      "[CV 4/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 4/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  40.1s\n",
      "[CV 5/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 5/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  38.0s\n",
      "[CV 1/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 1/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  41.4s\n",
      "[CV 2/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 2/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  38.9s\n",
      "[CV 3/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 3/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  38.4s\n",
      "[CV 4/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 4/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  33.3s\n",
      "[CV 5/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 5/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  35.8s\n",
      "[CV 1/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 1/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  36.3s\n",
      "[CV 2/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 2/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  35.1s\n",
      "[CV 3/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 3/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  36.8s\n",
      "[CV 4/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 4/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  38.9s\n",
      "[CV 5/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 5/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  40.8s\n",
      "[CV 1/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 1/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  44.0s\n",
      "[CV 2/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 2/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  37.7s\n",
      "[CV 3/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 3/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  38.9s\n",
      "[CV 4/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 4/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  37.9s\n",
      "[CV 5/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 5/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  39.8s\n",
      "[CV 1/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 1/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  40.6s\n",
      "[CV 2/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 2/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  39.0s\n",
      "[CV 3/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 3/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  39.5s\n",
      "[CV 4/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 4/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  37.8s\n",
      "[CV 5/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 5/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  35.5s\n",
      "[CV 1/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 1/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time=  36.4s\n",
      "[CV 2/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 2/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time=  39.6s\n",
      "[CV 3/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 3/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time=  42.0s\n",
      "[CV 4/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 4/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time=  38.2s\n",
      "[CV 5/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 5/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time=  38.4s\n",
      "[CV 1/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 1/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  37.4s\n",
      "[CV 2/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 2/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  38.1s\n",
      "[CV 3/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 3/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  37.5s\n",
      "[CV 4/5; 41/56] START neuron1=40, neuron2=2.....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  38.0s\n",
      "[CV 5/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 5/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  38.6s\n",
      "[CV 1/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 1/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  39.0s\n",
      "[CV 2/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 2/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  39.1s\n",
      "[CV 3/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 3/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  40.4s\n",
      "[CV 4/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 4/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  40.2s\n",
      "[CV 5/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 5/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  37.7s\n",
      "[CV 1/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 1/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  35.7s\n",
      "[CV 2/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 2/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  34.7s\n",
      "[CV 3/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 3/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  35.0s\n",
      "[CV 4/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 4/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  40.6s\n",
      "[CV 5/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 5/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  39.9s\n",
      "[CV 1/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 1/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time=  37.3s\n",
      "[CV 2/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 2/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time=  36.9s\n",
      "[CV 3/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 3/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time=  37.1s\n",
      "[CV 4/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 4/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time=  38.4s\n",
      "[CV 5/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 5/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time=  38.9s\n",
      "[CV 1/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 1/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time=  39.6s\n",
      "[CV 2/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 2/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time=  38.1s\n",
      "[CV 3/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 3/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time=  39.8s\n",
      "[CV 4/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 4/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time=  39.1s\n",
      "[CV 5/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 5/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time=  38.6s\n",
      "[CV 1/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 1/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time=  33.9s\n",
      "[CV 2/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 2/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time=  38.6s\n",
      "[CV 3/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 3/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time=  36.5s\n",
      "[CV 4/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 4/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time=  37.4s\n",
      "[CV 5/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 5/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time=  38.1s\n",
      "[CV 1/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 1/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time=  36.4s\n",
      "[CV 2/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 2/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time=  37.6s\n",
      "[CV 3/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 3/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time=  34.8s\n",
      "[CV 4/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 4/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time=  38.3s\n",
      "[CV 5/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 5/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time=  34.9s\n",
      "[CV 1/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 1/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time=  37.7s\n",
      "[CV 2/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 2/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time=  41.1s\n",
      "[CV 3/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 3/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time=  36.4s\n",
      "[CV 4/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 4/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time=  35.2s\n",
      "[CV 5/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 5/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time=  35.9s\n",
      "[CV 1/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 1/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time=  35.1s\n",
      "[CV 2/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 2/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time=  35.9s\n",
      "[CV 3/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 3/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time=  33.4s\n",
      "[CV 4/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 4/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time=  37.9s\n",
      "[CV 5/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 5/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time=  35.1s\n",
      "[CV 1/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 1/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  36.7s\n",
      "[CV 2/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 2/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  34.9s\n",
      "[CV 3/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 3/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  35.6s\n",
      "[CV 4/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 4/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  35.8s\n",
      "[CV 5/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 5/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  41.2s\n",
      "[CV 1/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 1/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  33.8s\n",
      "[CV 2/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 2/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  36.8s\n",
      "[CV 3/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 3/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  39.2s\n",
      "[CV 4/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 4/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  36.7s\n",
      "[CV 5/5; 51/56] START neuron1=50, neuron2=8.....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  35.9s\n",
      "[CV 1/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 1/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  36.1s\n",
      "[CV 2/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 2/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  35.6s\n",
      "[CV 3/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 3/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  35.2s\n",
      "[CV 4/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 4/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  34.0s\n",
      "[CV 5/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 5/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  33.8s\n",
      "[CV 1/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 1/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time=  36.5s\n",
      "[CV 2/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 2/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time=  42.0s\n",
      "[CV 3/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 3/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time=  37.4s\n",
      "[CV 4/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 4/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time=  35.8s\n",
      "[CV 5/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 5/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time=  37.0s\n",
      "[CV 1/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 1/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  35.4s\n",
      "[CV 2/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 2/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  38.0s\n",
      "[CV 3/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 3/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  35.8s\n",
      "[CV 4/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 4/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  36.8s\n",
      "[CV 5/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 5/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  33.9s\n",
      "[CV 1/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 1/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  36.1s\n",
      "[CV 2/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 2/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  37.6s\n",
      "[CV 3/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 3/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  37.3s\n",
      "[CV 4/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 4/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  36.3s\n",
      "[CV 5/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 5/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  36.7s\n",
      "[CV 1/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 1/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  36.3s\n",
      "[CV 2/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 2/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  35.6s\n",
      "[CV 3/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 3/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  36.8s\n",
      "[CV 4/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 4/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  34.9s\n",
      "[CV 5/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 5/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  35.1s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16,20,30,40,50]\n",
    "neuron2 = [2,4,8,20,30,40,50,60]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5d28061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 60}\n"
     ]
    }
   ],
   "source": [
    "#Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ee858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get best learning rate as 0.001 and dropout rate as 0 and best neurons as 4 and 2, so now we can build final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a091a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a174e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.3,random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da6ac14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10527, 10), (4512, 10), (10527,), (4512,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91fda74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optmizer =RMSprop(0.001)\n",
    "model_new=keras.Sequential([\n",
    "    keras.layers.Dense(4,input_dim =(n_features),activation='relu'),\n",
    "    keras.layers.Dense(2,activation ='relu')\n",
    "])\n",
    "model_new.compile(optimizer =optmizer,loss= 'mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf16da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.6997 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.4824 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.4750 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.4739 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.4735 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.4733 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.4733 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.4732 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.4731 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.4731 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4a74a1900>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value =42;\n",
    "import random\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "model_new.fit(X_train, y_train, epochs=10, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6daccecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4929099678993225, 0.0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6aebb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae44dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab4d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365cd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48e2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
